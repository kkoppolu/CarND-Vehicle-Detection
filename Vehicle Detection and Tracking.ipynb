{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import cv2\n",
    "from random import randint, sample\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from scipy.ndimage.measurements import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from collections import deque\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Raed the directory of images and store the file names\"\"\"\n",
    "def read_dir(dirname, extension):\n",
    "    imgtypes = os.listdir(dirname)\n",
    "    results = []\n",
    "    for imtype in imgtypes:\n",
    "        npath= dirname + imtype + '/*.' + extension\n",
    "        results.extend(glob.glob(npath))\n",
    "    return results\n",
    "\n",
    "\"\"\"Read the data set and return the image file names\"\"\"\n",
    "def read_dataset():\n",
    "    v_images = read_dir('vehicles/', 'png')\n",
    "    nv_images = read_dir('non-vehicles/', 'png')\n",
    "    return (v_images, nv_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction/Image Processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Get HOG features of the image and optionally the HOG visualization\"\"\"\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis, feature_vec):\n",
    "    \n",
    "    transform_sqrt=False # this does not work for -ve values in img\n",
    "    block_norm='L2-Hys'\n",
    "    \n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm=block_norm,\n",
    "                                  transform_sqrt=transform_sqrt, visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                      cells_per_block=(cell_per_block, cell_per_block), block_norm=block_norm,\n",
    "                      transform_sqrt=transform_sqrt, visualise=vis, feature_vector=feature_vec)\n",
    "        \n",
    "        if (np.isnan(np.min(features))):\n",
    "            from IPython.core.debugger import Tracer; Tracer()() \n",
    "        return features\n",
    "    \n",
    "\"\"\"Get the binned spatial features of the image\"\"\"  \n",
    "def bin_spatial(img, size):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "\"\"\"Get the color histogram features of the image\"\"\"  \n",
    "def color_hist(img, nbins):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "\"\"\"Convert the image from one color space to the other\"\"\"\n",
    "def convert_color(image, color_space):\n",
    "    if color_space == 'RGB':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    elif color_space == 'HSV':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif color_space == 'LUV':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif color_space == 'HLS':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    elif color_space == 'YUV':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    elif color_space == 'YCrCb':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    else: \n",
    "        feature_image = np.copy(image)   \n",
    "    return feature_image\n",
    "    \n",
    "\"\"\"Extract spatial, color and/or HOG features of the images per the specifications\"\"\"\n",
    "def extract_features(imgs, color_space, spatial_size,\n",
    "                    hist_bins, orient, pix_per_cell, cell_per_block, hog_channel,\n",
    "                    spatial_feat, hist_feat, hog_feat):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = cv2.imread(file)\n",
    "        image = image.astype(np.float32)\n",
    "        feature_image = convert_color(image, color_space)  \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            color_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(color_features)\n",
    "        if hog_feat == True:\n",
    "            # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "            \n",
    "        features.append(np.concatenate(file_features))\n",
    "            \n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n",
    "\"\"\"Extract spatial,color and/or HOG features for a single image\n",
    "Optionally return the HOG visualization of the image\"\"\"\n",
    "def single_img_features(img, color_space, spatial_size,\n",
    "                        hist_bins, orient, \n",
    "                        pix_per_cell, cell_per_block, hog_channel, vis,\n",
    "                        spatial_feat, hist_feat, hog_feat):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    feature_image = convert_color(img, color_space) \n",
    "        \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features, hog_image = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=vis, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    if vis == True:\n",
    "        #9) Return concatenated array of features\n",
    "        return np.concatenate(img_features), hog_image\n",
    "    else:\n",
    "        #9) Return concatenated array of features\n",
    "        return np.concatenate(img_features)\n",
    "\n",
    "    \n",
    "\"\"\"Define a function that takes an image, \n",
    "start and stop positions in both x and y, \n",
    "window size (x and y dimensions),  \n",
    "and overlap fraction (for both x and y)\"\"\"\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "\n",
    "\"\"\"Define a function to draw bounding boxes\"\"\"\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "\n",
    "\"\"\"Define a function you will pass an image \n",
    "and the list of windows to be searched (output of slide_windows())\"\"\"\n",
    "def search_windows(img, windows, clf, scaler, color_space, \n",
    "                    spatial_size, hist_bins, \n",
    "                    orient, pix_per_cell, cell_per_block, hog_channel, \n",
    "                    spatial_feat, hist_feat, hog_feat):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, vis=False,\n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = np.array(features).reshape(1, -1)\n",
    "        test_features = scaler.transform(test_features)\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows\n",
    "\n",
    "\n",
    "\"\"\"Define a function that visualizes the given list of images and titles \n",
    "on the figure provided\n",
    "\n",
    "Keyword arguments:\n",
    "fig -- Figure to visualize on\n",
    "rows - Number of image rows\n",
    "cols - Number of image columns\n",
    "imgs - Images to visualize\n",
    "titles - Titles of the images to visualize\n",
    "\"\"\"\n",
    "def visualize(fig, rows, cols, imgs, titles):\n",
    "    for i, img in enumerate(imgs):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.title(i+1)\n",
    "        img_dims = len(img.shape)\n",
    "        if img_dims < 3:\n",
    "            plt.imshow(img, cmap='hot')\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        plt.title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature parameters\n",
    "color_space = 'YCrCb'\n",
    "orient = 9\n",
    "pix_per_cell=8\n",
    "cell_per_block=2\n",
    "hog_channel='ALL'\n",
    "spatial_size = (32,32)\n",
    "hist_bins=32\n",
    "spatial_feat=True\n",
    "hist_feat=True\n",
    "hog_feat=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\"\"\"Visualize some samples of the data set by plotting them \n",
    "and their corresponding HOG image\n",
    "\n",
    "Keyword argumets:\n",
    "car_images -- Car images\n",
    "not_car_images - Images that are not of cars\n",
    "num_samples - Number of samples to visualize\n",
    "\"\"\"\n",
    "def sample_feature_visualization(car_images, not_car_images, num_samples):\n",
    "    for i in range(0, num_samples):\n",
    "        car_image = cv2.imread(car_images[randint(0, len(car_images))])\n",
    "        rgb_car = cv2.cvtColor(car_image, cv2.COLOR_BGR2RGB)\n",
    "        car_image = np.array(car_image).astype(np.float32)\n",
    "        not_car_image = cv2.imread(not_car_images[randint(0, len(not_car_images))])\n",
    "        rgb_not_car = cv2.cvtColor(not_car_image, cv2.COLOR_BGR2RGB)\n",
    "        not_car_image = np.array(not_car_image).astype(np.float32)\n",
    "        \n",
    "        print (\"Pixel Range: Min - {}. Max - {}\".format(np.min(car_image), np.max(car_image)))\n",
    "\n",
    "\n",
    "        car_features, car_hog_image = single_img_features(car_image, \n",
    "                                         color_space=color_space,\n",
    "                                         spatial_size=spatial_size, \n",
    "                                         hist_bins=hist_bins,\n",
    "                                         orient=orient,\n",
    "                                         pix_per_cell=8,\n",
    "                                         cell_per_block=2,\n",
    "                                         hog_channel=0,\n",
    "                                         vis=True,\n",
    "                                         spatial_feat=spatial_feat,\n",
    "                                         hist_feat=hist_feat,\n",
    "                                         hog_feat=hog_feat)\n",
    "        not_car_features, not_car_hog_image = single_img_features(not_car_image, \n",
    "                                         color_space=color_space,\n",
    "                                         spatial_size=spatial_size, \n",
    "                                         hist_bins=hist_bins,\n",
    "                                         orient=orient,\n",
    "                                         pix_per_cell=8,\n",
    "                                         cell_per_block=2,\n",
    "                                         hog_channel=0,\n",
    "                                         vis=True,\n",
    "                                         spatial_feat=spatial_feat,\n",
    "                                         hist_feat=hist_feat,\n",
    "                                         hog_feat=hog_feat)\n",
    "\n",
    "        images = [rgb_car, car_hog_image, rgb_not_car, not_car_hog_image]\n",
    "        titles = ['Car', 'Car HOG', 'Not Car', 'Not Car HOG']\n",
    "        fig = plt.figure(figsize=(12,3))\n",
    "        visualize(fig, 1, 4, images, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(v_images, nv_images) = read_dataset()\n",
    "print (\"Number of vehicle images: {}\".format(len(v_images)))\n",
    "print (\"Number of non-vehicle images: {}\".format(len(nv_images)))\n",
    "\n",
    "sample_feature_visualization(v_images, nv_images, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Train an SVC classification model on the given set of \n",
    "car and not-car images\n",
    "\n",
    "Keyword arguments:\n",
    "car_images -- Images of cars\n",
    "not_car_images -- Images that are not of cars\n",
    "\"\"\"\n",
    "def train(car_images, not_car_images):\n",
    "\n",
    "    test_cars = np.array(car_images)\n",
    "    test_notcars = np.array(not_car_images)\n",
    "\n",
    "    # get features\n",
    "    car_features = extract_features(test_cars, \n",
    "                                 color_space=color_space,\n",
    "                                 spatial_size=spatial_size, \n",
    "                                 hist_bins=hist_bins,\n",
    "                                 orient=orient,\n",
    "                                 pix_per_cell=pix_per_cell,\n",
    "                                 cell_per_block=cell_per_block,\n",
    "                                 hog_channel=hog_channel,\n",
    "                                 spatial_feat=spatial_feat,\n",
    "                                 hist_feat=hist_feat,\n",
    "                                 hog_feat=hog_feat)\n",
    "    not_car_features = extract_features(test_notcars, \n",
    "                                     color_space=color_space,\n",
    "                                     spatial_size=spatial_size, \n",
    "                                     hist_bins=hist_bins,\n",
    "                                     orient=orient,\n",
    "                                     pix_per_cell=pix_per_cell,\n",
    "                                     cell_per_block=cell_per_block,\n",
    "                                     hog_channel=hog_channel,\n",
    "                                     spatial_feat=spatial_feat,\n",
    "                                     hist_feat=hist_feat,\n",
    "                                     hog_feat=hog_feat)\n",
    "    \n",
    "    X = np.vstack((car_features, not_car_features)).astype(np.float64)       \n",
    "    \n",
    "    print (\"Training feature shape: {}\".format(X.shape))\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n",
    "\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        scaled_X, y, test_size=0.1, random_state=rand_state)\n",
    "\n",
    "    clf = SVC(C=10, kernel='rbf')\n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "\n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(clf.score(X_test, y_test), 4))\n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    \n",
    "    return (clf, X_scaler) # return the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf, scaler = train(v_images, nv_images)\n",
    "\n",
    "# persist the model\n",
    "scaler_file = 'scaler.pk'\n",
    "model_file = 'model.pk'\n",
    "joblib.dump(clf, model_file)\n",
    "joblib.dump(scaler, scaler_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test Classifier on test images - Slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_model_file = 'model.pk'\n",
    "load_scaler_file='scaler.pk'\n",
    "\n",
    "clf = joblib.load(load_model_file)\n",
    "scaler = joblib.load(load_scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test images\n",
    "test_img_path = 'test_images/'\n",
    "test_images = glob.glob(test_img_path + '*.jpg')\n",
    "print (\"Number of test images: {}\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "images=[]\n",
    "titles = []\n",
    "y_start_stop=[400,680]\n",
    "overlap=0.5\n",
    "xy_window=(96,96)\n",
    "\n",
    "for img_file in test_images:\n",
    "    t1 = time.time()\n",
    "    img = cv2.imread(img_file)\n",
    "    draw_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)\n",
    "    \n",
    "    windows = slide_window(img, x_start_stop=[None,None], y_start_stop=y_start_stop,\n",
    "                          xy_window=xy_window, xy_overlap=(overlap, overlap))\n",
    "    \n",
    "    hot_windows = search_windows(img, windows, clf, scaler, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block,\n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    \n",
    "    window_img = draw_boxes(draw_img, hot_windows, color=(0, 0, 255), thick=6)\n",
    "    images.append(window_img)\n",
    "    titles.append('')\n",
    "    print (\"{} seconds to process one image. Windows: {}\".format(time.time()-t1, len(windows)))\n",
    "\n",
    "fig = plt.figure(figsize=(12,18))\n",
    "visualize(fig, 5, 2, images, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image processing - Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"A class that processes the given image using the sliding window\n",
    "approach and draws bounding boxes around cars\n",
    "\"\"\"\n",
    "class ImageProcessor:\n",
    "    \"\"\"Constructor\n",
    "    \n",
    "    Keyword arguments:\n",
    "    smooth_factor -- Number of heat maps to smooth output over. \n",
    "    Moving average is used\n",
    "    clf -- The classifier to use\n",
    "    scaler -- THe feature scaler to use\n",
    "    parameters -- Parameters for the sliding window. The format is:\n",
    "    an array of tuples: (scale, ystart, yend)\n",
    "    threshold -- Number of detections to be considered as a car\"\"\"\n",
    "    def __init__(self, smooth_factor, clf, scaler, parameters, threshold):\n",
    "        self.recent_heatmaps = deque(maxlen=smooth_factor)\n",
    "        self.clf = clf\n",
    "        self.scaler = scaler\n",
    "        self.parameters = parameters\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    \"\"\"Apply a threshold on the given heat map\"\"\"\n",
    "    def apply_heat_threshold(self, heatmap):\n",
    "        heatmap[heatmap < self.threshold] = 0\n",
    "        return heatmap\n",
    "    \n",
    "    \"\"\"Draw bounding boxes given the labels of the image\"\"\"\n",
    "    def draw_labeled_bboxes(self, img, labels):\n",
    "        for car_number in range(1, labels[1] + 1):\n",
    "            # find pixels for the car_number\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "\n",
    "            # identify x and y\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "\n",
    "            # draw a bounding box based on mix/max values\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "\n",
    "            # draw the rectangle\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0, 0, 255), 6)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \"\"\"Find the cars in the given image and draw bounding boxes around them\"\"\"\n",
    "    def find_cars(self, img):\n",
    "        \n",
    "        # output image in RGB\n",
    "        draw_img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # input image as float\n",
    "        img = img.astype(np.float32)\n",
    "            \n",
    "        # find the aggregate heat map for all y and scale parameters\n",
    "        overall_heatmap = np.zeros_like(img[:,:,0])\n",
    "        for scale,ystart,yend in self.parameters:\n",
    "            heatmap = self.find_cars_single_param(img, ystart,yend,scale)\n",
    "            overall_heatmap = np.add(overall_heatmap, heatmap)\n",
    "                   \n",
    "        # record it\n",
    "        self.recent_heatmaps.append(overall_heatmap)\n",
    "        # smooth out\n",
    "        overall_heatmap = np.average(self.recent_heatmaps, axis=0)\n",
    "        # threshold and return\n",
    "        overall_heatmap = self.apply_heat_threshold(overall_heatmap)\n",
    "        \n",
    "        # label and bbox it\n",
    "        labels = label(overall_heatmap)\n",
    "        draw_img = self.draw_labeled_bboxes(draw_img, labels)\n",
    "        \n",
    "        return draw_img, overall_heatmap\n",
    "        \n",
    "    \"\"\"Find the cars in the given image and return the heatmap\n",
    "    \n",
    "    Keyword arguments:\n",
    "    img -- Image to find cars in\n",
    "    ystart -- Y co-ordinate to start search from\n",
    "    yend -- Y co-ordinate to end search at\n",
    "    scale -- Scale of the sliding window. A scale of 1 is 64 X 64\"\"\"\n",
    "    def find_cars_single_param(self, img, ystart, yend, scale):\n",
    "        t = time.time()\n",
    "\n",
    "        search_img=img[ystart:yend,:,:]\n",
    "        ctrans_search=convert_color(search_img,color_space)\n",
    "\n",
    "        if scale != 1:\n",
    "            imshape = ctrans_search.shape\n",
    "            # resize the image instead of resizing the boxes. The effect is the same\n",
    "            ctrans_search = cv2.resize(ctrans_search, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "\n",
    "        # get the hog features of the scaled image\n",
    "        ch1 = ctrans_search[:,:,0]\n",
    "        ch2 = ctrans_search[:,:,1]\n",
    "        ch3 = ctrans_search[:,:,2]\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=False)\n",
    "\n",
    "        # Define blocks and steps\n",
    "        width = ch1.shape[1]\n",
    "        height = ch1.shape[0]\n",
    "        nxcells = width // pix_per_cell\n",
    "        nycells = height // pix_per_cell\n",
    "\n",
    "        # original window size\n",
    "        window = 64\n",
    "        window_cells = window // pix_per_cell\n",
    "\n",
    "        # blocks are like 1 d conv moving 1 cell at a time\n",
    "        nxblocks = nxcells - cell_per_block + 1 \n",
    "        nyblocks = nycells - cell_per_block + 1\n",
    "        nblocks_per_window = window_cells - cell_per_block + 1 \n",
    "\n",
    "        cells_per_step=2 # 75% overlap\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "        #print (\"nxblocks: {}, nyblocks: {}\".format(nxblocks, nyblocks))\n",
    "        #print (\"window blocks: {}\".format(nblocks_per_window))\n",
    "        #print (\"nxsteps: {}, nysteps: {}\".format(nxsteps, nysteps))\n",
    "\n",
    "        heatmap = np.zeros_like(img[:,:,0])\n",
    "        count=0 # number of boxes\n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                count += 1\n",
    "\n",
    "                ypos = yb * cells_per_step\n",
    "                xpos = xb * cells_per_step\n",
    "\n",
    "                # extract HOG for this patch\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                xleft = xpos * pix_per_cell\n",
    "                ytop = ypos * pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_search[ytop:ytop+window, xleft:xleft+window], (window,window))\n",
    "\n",
    "                # Get color features\n",
    "                spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "                # careful of the order!\n",
    "                features = np.hstack((spatial_features, hist_features, hog_features)).reshape(1,-1)\n",
    "                # scale features and make the prediction\n",
    "                scaled_features = self.scaler.transform(features)\n",
    "                prediction = self.clf.predict(scaled_features)\n",
    "\n",
    "                if prediction == 1:\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    xbox_right = xbox_left + win_draw\n",
    "                    ytop_draw = ystart + np.int(ytop*scale)\n",
    "                    ybot_draw = ytop_draw + win_draw\n",
    "\n",
    "                    #cv2.rectangle(draw_img, \n",
    "                    #              (xbox_left, ytop_draw), \n",
    "                    #              (xbox_right, ybot_draw),\n",
    "                    #              (0,0,255), 6)\n",
    "                    heatmap[ytop_draw:ybot_draw, xbox_left:xbox_right] += 1\n",
    "\n",
    "        #print(\"{} seconds to run for {} windows\".format(time.time() - t, count))\n",
    "        \n",
    "        return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "out_images= []\n",
    "out_titles = []\n",
    "params = [(1.0, 400, 480), (1.5, 400, 680), (2.5, 480, 680)]\n",
    "proc = ImageProcessor(smooth_factor=1, clf=clf, scaler=scaler, parameters=params, threshold=1)\n",
    "for img_file in test_images:\n",
    "    img=cv2.imread(img_file)\n",
    "    draw_img, heatmap = proc.find_cars(img)   \n",
    "    \n",
    "    out_images.append(draw_img)\n",
    "    out_images.append(heatmap)\n",
    "    out_titles.append(img_file[-9:])\n",
    "    out_titles.append(img_file[-9:])\n",
    "    \n",
    "fig = plt.figure(figsize=(12,24))\n",
    "visualize(fig, 8, 2, out_images, out_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"A class to process video frames and draw \n",
    "bounding boxes on cars detected\"\"\"\n",
    "class VideoFrameProcessor:\n",
    "    \"\"\"Constructor\"\"\"\n",
    "    def __init__(self):\n",
    "        params = [(1.0, 400, 480), (1.5, 400, 680), (2.5, 480, 680)]\n",
    "        self.proc = ImageProcessor(smooth_factor=10, clf=clf, scaler=scaler, parameters=params, threshold=3)\n",
    "        \n",
    "    \"\"\"Process the given video frame\"\"\"\n",
    "    def process_video_frame(self, img):\n",
    "        input_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        draw_img, heat_map = self.proc.find_cars(input_img)\n",
    "\n",
    "        return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test.mp4\n",
      "[MoviePy] Writing video test.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [07:24<00:11, 11.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output = 'test.mp4'\n",
    "clip = VideoFileClip(\"test_video.mp4\")\n",
    "vproc = VideoFrameProcessor()\n",
    "test_clip = clip.fl_image(vproc.process_video_frame)\n",
    "test_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_output = 'project.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "vproc = VideoFrameProcessor()\n",
    "proj_clip = clip.fl_image(vproc.process_video_frame)\n",
    "proj_clip.write_videofile(proj_output, audio=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
